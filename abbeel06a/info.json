{
    "abstract": "We study the computational and sample complexity of parameter and\nstructure learning in graphical models.  Our main result shows that\nthe class of factor graphs with bounded degree can be learned in\npolynomial time and from a polynomial number of training examples,\nassuming that the data is generated by a network in this class.  This\nresult covers both parameter estimation for a known network structure\nand structure learning.  It implies as a corollary that we can learn\nfactor graphs for both Bayesian networks and Markov networks of\nbounded degree, in polynomial time and sample complexity. Importantly,\nunlike standard maximum likelihood estimation algorithms, our method\ndoes not require inference in the underlying network, and so applies\nto networks where inference is intractable.  We also show that the\nerror of our learned model degrades gracefully when the generating\ndistribution is not a member of the target class of networks. In\naddition to our main result, we show that the sample complexity of\nparameter learning in graphical models has an <i>O</i>(1) dependence\non the number of variables in the model when using the KL-divergence\nnormalized by the number of variables as the performance criterion.",
    "authors": [
        "Pieter Abbeel",
        "Daphne Koller",
        "Andrew Y. Ng"
    ],
    "id": "abbeel06a",
    "issue": 63,
    "pages": [
        1743,
        1788
    ],
    "title": "Learning Factor Graphs in Polynomial Time and Sample Complexity",
    "volume": "7",
    "year": "2006"
}